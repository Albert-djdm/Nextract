{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Albert de Jamblinne de Meux\n",
    "# thealbertsmail@gmail.com\n",
    "# All right reserved.\n",
    "#\n",
    "# Under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License\n",
    "# Read the LICENSE.TXT for detail or https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode\n",
    "\n",
    "\n",
    "# Extraction of the issuer Name, Method used during the diHub Hackaton by the Mighty python tream for\n",
    "# the final prediction.\n",
    "\n",
    "# This is the refactored version. with some simplifications and generalisation and a lot more comments.\n",
    "\n",
    "# You need the ordered_set and html2text library... (pip install ordered_set html2text)\n",
    "\n",
    "# Training was done manually, improvement could probably be obtained by further training\n",
    "# and atomisation of this training which was not done due to the lack of time\n",
    "# (and because training the model is not straightforward... or at least for me, if\n",
    "# you see a method to do it, I'm will be more than happy to learn it ;) )\n",
    "#\n",
    "# Notice that all the data sets and reference data are confidential. Therefore I have\n",
    "# not included any of those here, to use this code you will obviously need these or similar\n",
    "# one... (Notice that I do not have anymore access to those data myself so there is no point asking me for them !!!)\n",
    "\n",
    "# This code only extract the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create the model\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# First we create the model and save it.\n",
    "from NEModel import matcher,extractor\n",
    "import ordered_set\n",
    "\n",
    "# create the extraction model,\n",
    "with open('../../company.csv','r') as f: # list of all the companies from which we have to choOse from.\n",
    "    c = f.readlines()\n",
    "    \n",
    "companies =  ordered_set.OrderedSet()\n",
    "\n",
    "for item in c[1:]:\n",
    "    companies.add(item.strip('\\n\", '))\n",
    "\n",
    "# some synonymes\n",
    "synonymes =[('aktiengesellschaft','ag'),\n",
    "    ('Limited liability company','llc'),('Public limited company','plc'),('incorporation','inc'),\n",
    "    ('Sociedad por Acciones','sa'),('Public Limited','ltd'),('int','international'), ('london','bishopsgate 110'),\n",
    "    ('paris','fort dup 11046'),('london','great winche'),('london','golden lane'),('new world development','nwd'),\n",
    "    ('england ','bishopsgate 110'),\n",
    "    ('london','bishopsgate 110'),\n",
    "    ('acting through its london branch','great winche'),\n",
    "    ('acting through its london branch','golden lane'),\n",
    "    ('incorporated with limited liability in england and wales','bishopsgate 110'),\n",
    "    ('rubbermaid inc','brands inc'),\n",
    "    ('dexia funding netherlands','belfius financing company sa'),\n",
    "    ('province of british columbia','government of the province of british columbia'),\n",
    "    ('london branch','one cabot square')]\n",
    "\n",
    "match = matcher(companies,synonymes)\n",
    "\n",
    "extract = extractor(match, ('issue','issued'), ('issuer','issued'),\n",
    "                    ( 'linked to', 'share issuer', 'equity issuer', 'guarantor', 'dealer',\n",
    "                      'of the issue of securities', 'lead manager','notes and certificates of'),\n",
    "                    (('BARCLAYS BANK PLC Incorporated with limited liability in england and wales',\n",
    "                      'BARCLAYS BANK PLC','BARCLAYS BANK PLC BISHOPSGATE (110)'),),\n",
    "                    start='+')\n",
    "\n",
    "extract.save('extractor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it in serial\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "# Now we can extract the data\n",
    "import os\n",
    "import Issuer_extraction.txt_processing as tp\n",
    "import Issuer_extraction.label_data as de\n",
    "from NEModel import matcher,extractor\n",
    "import ordered_set\n",
    "\n",
    "folder = '../../Newdata/train' # where are the data...\n",
    "# get the files (this is mapping fileid to file path.)\n",
    "filesTxT = tp.get_files(os.path.join(folder,'txt')) # txt files\n",
    "filesHtml = tp.get_files(os.path.join(folder,'html')) # html files\n",
    "\n",
    "# get the fileids for the data set (here for the training set...):\n",
    "d = de.data(folder='../../Newdata/train/')\n",
    "\n",
    "# get the extractor\n",
    "extract=extractor.from_file('extractor.pkl')\n",
    "\n",
    "# where to store the data.\n",
    "issuerDic = {}\n",
    "\n",
    "x = 0\n",
    "for isin in d.docid:  # for each isin in the data object created before\n",
    "   \n",
    "    if x > 100: # to limit the number of document to check\n",
    "        break\n",
    "    x += 1\n",
    "\n",
    "    f = d.docid[isin]  # get the file_ids, this is a set, because we can have many document.\n",
    "    issuer = None # the issuer, at the start we do not known...\n",
    "    for item in f:  # for each of these files\n",
    "        # get the txt from the file first.\n",
    "        txt = tp.get_text(filesTxT[item], raw=True)\n",
    "        #print txt\n",
    "        issuer = extract.extract(txt) # get the value\n",
    "        if issuer is None: # if it did not work, try the html file,\n",
    "            # I never test if this is really useful, but when I started, some txt files where bad\n",
    "            # while the html files was ok. Nevertheless I could not find a nice why to striping html tag,\n",
    "            # ofter I lose most of the structure, the one provided keep the structures which is much better...\n",
    "            txt = tp.get_text(filesHtml[item])\n",
    "            issuer = extract.extract(txt)\n",
    "\n",
    "        # if we find it, stop searching...\n",
    "        if issuer is not None:\n",
    "            break\n",
    "            \n",
    "    #print isin, issuer\n",
    "\n",
    "    if issuer is not None:\n",
    "        issuerDic[isin] = issuer\n",
    "    else:\n",
    "        issuerDic[isin] = '' # put an empty string for isin that where not found...\n",
    "\n",
    "p = {}\n",
    "for item in issuerDic:\n",
    "    p[item]=d.issuer[item][0]\n",
    "de.test(issuerDic,p)\n",
    "        \n",
    "# save the data in csv...\n",
    "de.to_csv('issuer.csv',issuerDic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "// version:\n",
    "--------------\n",
    "\n",
    "This is a fast solution, no the best one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import Issuer_extraction.txt_processing as tp\n",
    "import Issuer_extraction.label_data as de\n",
    "from NEModel import matcher,extractor\n",
    "\n",
    "import os\n",
    "import ordered_set\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "d = de.data(folder='../../Newdata/train/')\n",
    "folder = '../../Newdata/train' # where are the data...\n",
    "# get the extractor\n",
    "extract=extractor.from_file('extractor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Or we can try to do this in //\n",
    "\n",
    "def get_issuer(isins, extract, folder):\n",
    "    \"\"\"\n",
    "    Extract the issuer of a set of isin from a given folder.\n",
    "    \n",
    "    Args:\n",
    "        extract: the extractor use to get the issuer\n",
    "        folder: the path to the root folder (only train / final_test and / int_test folder)\n",
    "        isins: list of isin to be extracted.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the files (this is mapping fileid to file path.)\n",
    "    filesTxT = tp.get_files(os.path.join(folder,'txt')) # txt files\n",
    "    filesHtml = tp.get_files(os.path.join(folder,'html')) # html files\n",
    "\n",
    "    # get the fileids for the data set (here for the training set...):\n",
    "    d = de.data(folder=folder)\n",
    "    \n",
    "    # where to store the data.\n",
    "    issuerDic = {}\n",
    "    \n",
    "    for isin in isins:  # for each isin in the data object created before\n",
    "\n",
    "        f = d.docid[isin]  # get the file_ids, this is a set, because we can have many document.\n",
    "        issuer = None # the issuer, at the start we do not known...\n",
    "        for item in f:  # for each of these files\n",
    "            # get the txt from the file first.\n",
    "            txt = tp.get_text(filesTxT[item], raw=True)\n",
    "            #print txt\n",
    "            issuer = extract.extract(txt) # get the value\n",
    "            if issuer is None: # if it did not work, try the html file,\n",
    "                # I never test if this is really useful, but when I started, some txt files where bad\n",
    "                # while the html files was ok. Nevertheless I could not find a nice why to striping html tag,\n",
    "                # ofter I lose most of the structure, the one provided keep the structures which is much better...\n",
    "                txt = tp.get_text(filesHtml[item])\n",
    "                issuer = extract.extract(txt)\n",
    "\n",
    "            # if we find it, stop searching...\n",
    "            if issuer is not None:\n",
    "                break\n",
    "\n",
    "        if issuer is not None:\n",
    "            issuerDic[isin] = issuer\n",
    "        else:\n",
    "            issuerDic[isin] = '' # put an empty string for isin that where not found...\n",
    "\n",
    "    return issuerDic\n",
    "\n",
    "\n",
    "def get_issuer_multi(extract, folder, isins, ncpu):\n",
    "    \"\"\"\n",
    "    Extract the issuer of a set of isin from a given folder.\n",
    "    \n",
    "    multi process version.\n",
    "    \n",
    "    Args:\n",
    "        extract: the extractor use to get the issuer\n",
    "        folder: the path to the root folder (only train / final_test and / int_test folder)\n",
    "        isins: list of isin to be extracted.\n",
    "        ncpu: use ncpu core.\n",
    "    \"\"\"\n",
    "    l = len(isins) / ncpu\n",
    "    groups = []\n",
    "    for x in xrange(0,ncpu-1):\n",
    "        groups.append(isins[x*l:(x+1)*l])\n",
    "    groups.append(isins[(x+1)*l:])\n",
    "    \n",
    "    p = Pool(ncpu)\n",
    "        \n",
    "    f = partial(get_issuer, extract=extract, folder=folder)\n",
    "        \n",
    "    result = p.map(f, groups)\n",
    "\n",
    "    rf={}\n",
    "    for r in result:\n",
    "        rf.update(r)\n",
    "        \n",
    "    return rf\n",
    "\n",
    "issuerDic = get_issuer_multi(extract, folder, d.docid.keys()[:101], 2)\n",
    "\n",
    "p = {}\n",
    "for item in issuerDic:\n",
    "    p[item]=d.issuer[item][0]\n",
    "de.test(issuerDic,p)\n",
    "\n",
    "de.to_csv('issuer.csv',issuerDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
